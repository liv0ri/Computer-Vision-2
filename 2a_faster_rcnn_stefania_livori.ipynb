{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e8fcf5",
   "metadata": {},
   "source": [
    "# Faster R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0de06cd",
   "metadata": {},
   "source": [
    "Import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d4f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import json \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e94f5",
   "metadata": {},
   "source": [
    "Declare the possible classes of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e822c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = {\n",
    "  1: \"Stop\",\n",
    "  2: \"No Entry (One Way)\",\n",
    "  3: \"Pedestrian Crossing\",\n",
    "  4: \"Roundabout Ahead\",\n",
    "  5: \"No Through Road (T-Sign)\",\n",
    "  6: \"Blind-Spot Mirror (Convex)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "167b107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignsDataset(Dataset):\n",
    "    def __init__(self, root, annFile, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "\n",
    "        with open(annFile) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        self.images = data[\"images\"]\n",
    "        self.annotations = data[\"annotations\"]\n",
    "\n",
    "        # map image to annotations\n",
    "        self.imgToAnns = {img[\"id\"]: [] for img in self.images}\n",
    "        for ann in self.annotations:\n",
    "            self.imgToAnns[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_info = self.images[idx]\n",
    "        image_id = img_info[\"id\"]\n",
    "\n",
    "        img_path = os.path.join(self.root, img_info[\"file_name\"])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        anns = self.imgToAnns[image_id]\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        for ann in anns:\n",
    "            x, y, w, h = ann[\"bbox\"]\n",
    "            boxes.append([x, y, w, h])\n",
    "            labels.append(ann[\"category_id\"])\n",
    "\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": torch.tensor([image_id])\n",
    "        }\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62e66e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "\n",
    "    return T.Compose(transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c41cfc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/instances_signs.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mSignsDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/images\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannFile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/instances_signs.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m SignsDataset(\n\u001b[0;32m      8\u001b[0m     root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/images\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     annFile\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/instances_signs.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     transforms\u001b[38;5;241m=\u001b[39mget_transform(train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m )\n",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m, in \u001b[0;36mSignsDataset.__init__\u001b[1;34m(self, root, annFile, transforms)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m root\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m transforms\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mannFile\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      7\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\cv2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/instances_signs.json'"
     ]
    }
   ],
   "source": [
    "train_dataset = SignsDataset(\n",
    "    root=\"data/images\",\n",
    "    annFile=\"data/instances_signs.json\",\n",
    "    transforms=get_transform(train=True)\n",
    ")\n",
    "\n",
    "val_dataset = SignsDataset(\n",
    "    root=\"data/images\",\n",
    "    annFile=\"dataset/instances_signs.json\",\n",
    "    transforms=get_transform(train=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "    weights=\"DEFAULT\"\n",
    ")\n",
    "\n",
    "infeat = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(infeat, len(CLASS_NAMES) + 1)  # +1 for background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80618a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for imgs, targets in train_loader:\n",
    "        imgs = [img.to(device) for img in imgs]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(imgs, targets)\n",
    "        loss = sum(loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095a10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/fasterrcnn_signs.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARI3129",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
