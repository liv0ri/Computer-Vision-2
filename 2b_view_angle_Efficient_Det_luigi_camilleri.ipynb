{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "3ec050c1",
            "metadata": {},
            "source": [
                "# Task 2b: Attribute Detection (View Angle) with EfficientDet\n",
                "\n",
                "**Student:** Luigi Camilleri  \n",
                "**Student ID:** 0312805L    \n",
                "**Model:** EfficientDet (D2) \n",
                "\n",
                "\n",
                "This notebook implements a detector specifically for classifying the viewing angle of traffic signs using EfficientDet. It covers:\n",
                "1.  **Dataset Preparation**: Loading images and annotations.\n",
                "2.  **Model Training**: Fine Tuning a pretrained `EfficientDet` to detect and classify viewing angles.\n",
                "3.  **Evaluation**: Calculating F1-Scores.\n",
                "4.  **Inference & Analytics**: Visualisation and counting detections of viewing angles."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1c495c6f",
            "metadata": {},
            "outputs": [],
            "source": [
                "from __future__ import annotations\n",
                "\n",
                "# Standard library\n",
                "import importlib\n",
                "import subprocess\n",
                "import sys\n",
                "import json\n",
                "import os\n",
                "\n",
                "# Package bootstrap helper\n",
                "def ensure_package(pkg: str, import_name: str | None = None, pip_name: str | None = None):\n",
                "    try:\n",
                "        return importlib.import_module(import_name or pkg)\n",
                "    except ImportError:\n",
                "        pip_target = pip_name or pkg\n",
                "        print(f\"Installing missing package: {pip_target}\")\n",
                "        subprocess.check_call(\n",
                "            [sys.executable, \"-m\", \"pip\", \"install\", pip_target],\n",
                "            stdout=subprocess.DEVNULL\n",
                "        )\n",
                "        return importlib.import_module(import_name or pkg)\n",
                "\n",
                "# Ensure third-party packages\n",
                "torch = ensure_package(\"torch\")\n",
                "torchvision = ensure_package(\"torchvision\")\n",
                "plt = ensure_package(\"matplotlib.pyplot\", \"matplotlib.pyplot\", \"matplotlib\")\n",
                "np = ensure_package(\"numpy\")\n",
                "PIL = ensure_package(\"Pillow\", \"PIL\", \"pillow\")\n",
                "time = ensure_package(\"time\")\n",
                "ensure_package(\"tensorboard\")\n",
                "ensure_package(\"albumentations\")\n",
                "ensure_package(\"pycocotools\")\n",
                "ensure_package(\"effdet\")\n",
                "ensure_package(\"pandas\")\n",
                "\n",
                "# --- Explicit imports (clear & IDE-friendly) ---\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torch.utils.tensorboard import SummaryWriter\n",
                "import torchvision.transforms as T\n",
                "from PIL import Image\n",
                "import time\n",
                "import copy\n",
                "import albumentations as A\n",
                "from albumentations.pytorch import ToTensorV2\n",
                "from pycocotools.coco import COCO\n",
                "import pandas as pd\n",
                "\n",
                "# Custom/local utilities \n",
                "try:\n",
                "    from luigi_camilleri_utils import *\n",
                "except ImportError:\n",
                "    raise ImportError(\n",
                "        \"âŒ 'luigi_camilleri_utils' not found.\\n\"\n",
                "        \"Make sure 'luigi_camilleri_utils.py' is in the working directory \"\n",
                "        \"or on PYTHONPATH.\"\n",
                "    )\n",
                "\n",
                "# Reproducibility\n",
                "torch.manual_seed(42)\n",
                "\n",
                "print(\"Environment ready: all dependencies installed and imported.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a17732ed",
            "metadata": {},
            "source": [
                "## 1. Dataset Preparation"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a0dd0eed",
            "metadata": {},
            "source": [
                "\n",
                "I use the `SignsDataset` class from my utilities module."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cb54eff1",
            "metadata": {},
            "source": [
                "\n",
                "**Note:** Images are stored in `images` subfolder and annotations in `annotations` subfolder. These two subfolders are found in the `COCO-based_COCO_view_angle` folder."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c89be127",
            "metadata": {},
            "source": [
                "In each subfolder there are the data split into `train`, `val` and `test`. This is done to make sure that the results are reproducible."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "faf5da08",
            "metadata": {},
            "outputs": [],
            "source": [
                "DATA_DIR_TRAIN = \"Assignment Material/COCO-based_COCO_view_angle/images/train\" \n",
                "ANNOTATION_FILE_TRAIN = \"Assignment Material/COCO-based_COCO_view_angle/annotations/train.json\"\n",
                "\n",
                "DATA_DIR_VAL = \"Assignment Material/COCO-based_COCO_view_angle/images/val\"\n",
                "ANNOTATION_FILE_VAL = \"Assignment Material/COCO-based_COCO_view_angle/annotations/val.json\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "86886beb",
            "metadata": {},
            "source": [
                "The categories are also taken from the annotations file, this ensures that the categories are consistent. Additionally it avoids having mistakes or having to change the category list if the attribute type is changed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7b4b385e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build mapping: class_id -> class_name\n",
                "with open(ANNOTATION_FILE_TRAIN, \"r\") as f:\n",
                "    data = json.load(f)\n",
                "CLASS_ID_TO_NAME = {cat[\"id\"]: cat[\"name\"] for cat in data[\"categories\"]}\n",
                "NUM_CLASSES = len(CLASS_ID_TO_NAME)  \n",
                "# print(CLASS_ID_TO_NAME)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "be9636f2",
            "metadata": {},
            "source": [
                "### Initialize Dataset and DataLoaders"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c505a782",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data augmentation flag\n",
                "augmentation = True\n",
                "transform = A.Compose(\n",
                "    [\n",
                "        A.Resize(768, 768),  # EfficientDet expects fixed-size inputs\n",
                "        A.Normalize(\n",
                "            mean=(0.0, 0.0, 0.0),\n",
                "            std=(1.0, 1.0, 1.0),\n",
                "            max_pixel_value=255.0\n",
                "        ),\n",
                "        ToTensorV2()\n",
                "    ],\n",
                "    bbox_params=A.BboxParams(\n",
                "        format=\"coco\",\n",
                "        label_fields=[\"labels\"]\n",
                "    )\n",
                ")\n",
                "\n",
                "if augmentation:\n",
                "    train_transform = A.Compose(\n",
                "    [\n",
                "        A.Resize(768, 768),  # EfficientDet expects fixed-size inputs\n",
                "        A.HorizontalFlip(p=0.5),\n",
                "        A.RandomBrightnessContrast(p=0.3),\n",
                "        A.Affine(\n",
                "            scale=(0.9, 1.1),\n",
                "            translate_percent=(0.05, 0.05),\n",
                "            rotate=(-15, 15),\n",
                "            mode=0,\n",
                "            p=0.5\n",
                "        ),\n",
                "        A.Normalize(mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0)),\n",
                "        ToTensorV2()\n",
                "    ],\n",
                "    bbox_params=A.BboxParams(format=\"coco\", label_fields=[\"labels\"])\n",
                ")\n",
                "else:\n",
                "    train_transform = transform\n",
                "\n",
                "train_dataset = SignsDataset(\n",
                "    root=DATA_DIR_TRAIN,\n",
                "    annFile=ANNOTATION_FILE_TRAIN,\n",
                "    transforms=train_transform,\n",
                ")\n",
                "\n",
                "val_dataset = SignsDataset(\n",
                "    root=DATA_DIR_VAL,\n",
                "    annFile=ANNOTATION_FILE_VAL,\n",
                "    transforms=transform, \n",
                ")\n",
                "\n",
                "train_loader = DataLoader(\n",
                "    train_dataset, \n",
                "    batch_size=4, \n",
                "    shuffle=True, \n",
                "    collate_fn=lambda x: tuple(zip(*x)))\n",
                "\n",
                "val_loader = DataLoader(\n",
                "    val_dataset, \n",
                "    batch_size=2, \n",
                "    shuffle=False, \n",
                "    collate_fn=lambda x: tuple(zip(*x)))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "55512a72",
            "metadata": {},
            "source": [
                "## 2. Model Configuration\n",
                "Loading the EfficientDet model pre-trained on COCO and adapting proper number of classes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5a013121",
            "metadata": {},
            "outputs": [],
            "source": [
                "device = get_device()\n",
                "model, config = get_efficientdet_train(NUM_CLASSES)\n",
                "model = model.to(device)\n",
                "\n",
                "lr = 0.001\n",
                "weight_decay = 1e-4\n",
                "optimizer = torch.optim.AdamW(\n",
                "    model.parameters(),\n",
                "    lr=lr,\n",
                "    weight_decay=weight_decay\n",
                ")\n",
                "\n",
                "scheduler = torch.optim.lr_scheduler.StepLR(\n",
                "    optimizer, step_size=3, gamma=0.1\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ab856763",
            "metadata": {},
            "source": [
                "## 3. Training Loop\n",
                "\n",
                "Training for 25 epochs and evaluating on validation set after each epoch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "63402105",
            "metadata": {},
            "outputs": [],
            "source": [
                "num_epochs = 25\n",
                "train_losses = []\n",
                "val_f1_scores = []\n",
                "train_cls_losses = []\n",
                "train_box_losses = []\n",
                "best_epochs = 0\n",
                "best_f1 = 0\n",
                "best_model = None\n",
                "writer = SummaryWriter(\"runs/efficientdet_view_angle\")\n",
                "\n",
                "start_time = time.time()\n",
                "for epoch in range(num_epochs):\n",
                "    print(f\"\\nStarting Epoch {epoch+1}/{num_epochs}\")\n",
                "    losses = train_one_epoch(model, train_loader, optimizer, device)\n",
                "    \n",
                "    train_losses.append(losses[\"total\"])\n",
                "    train_cls_losses.append(losses[\"cls\"])\n",
                "    train_box_losses.append(losses[\"box\"])\n",
                "\n",
                "    writer.add_scalar(\"Loss/Total\", losses[\"total\"], epoch)\n",
                "    writer.add_scalar(\"Loss/Class\", losses[\"cls\"], epoch)\n",
                "    writer.add_scalar(\"Loss/Box\", losses[\"box\"], epoch)\n",
                "\n",
                "    scheduler.step()\n",
                "\n",
                "    f1 = f1_score_by_iou(model, val_loader, device, config)\n",
                "    val_f1_scores.append(f1)\n",
                "\n",
                "    if f1 > best_f1:\n",
                "        best_f1 = f1\n",
                "        best_model = copy.deepcopy(model)\n",
                "        best_epochs = epoch + 1\n",
                "\n",
                "    print(\n",
                "        f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
                "        f\"Total Loss: {losses['total']:.4f} | \"\n",
                "        f\"Cls Loss: {losses['cls']:.4f} | \"\n",
                "        f\"Box Loss: {losses['box']:.4f} | \"\n",
                "        f\"F1: {f1:.4f}\"\n",
                "    )\n",
                "\n",
                "writer.close()\n",
                "end_time = time.time()\n",
                "print(f\"Training completed in {end_time - start_time:.2f} seconds\")\n",
                "print(f\"Best F1 score: {best_f1:.4f} at epoch {best_epochs}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fc247de7",
            "metadata": {},
            "source": [
                "### Reload the best model only if needed"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d8a0051d",
            "metadata": {},
            "outputs": [],
            "source": [
                "reload = False\n",
                "if reload:\n",
                "    best_model, config = get_efficientdet_train(NUM_CLASSES)\n",
                "    best_model = best_model.to(device)\n",
                "    state_dict = torch.load(\n",
                "    'models/augmentation/efficientdet_epochs25_lr_0.0001_weight_0.0001_view_angle.pt',\n",
                "     map_location=device\n",
                "    )\n",
                "    best_model.load_state_dict(state_dict)\n",
                "    model = best_model.to(device)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "88fec303",
            "metadata": {},
            "source": [
                "### MAP Score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "37cf402e",
            "metadata": {},
            "outputs": [],
            "source": [
                "coco_gt = COCO(ANNOTATION_FILE_VAL)\n",
                "map_stats = evaluate_map(best_model, val_loader, device, coco_gt, config)\n",
                "\n",
                "metrics_names = [\n",
                "    \"mAP IoU=0.5:0.95\", \"mAP IoU=0.5\", \"mAP IoU=0.75\",\n",
                "    \"mAP small\", \"mAP medium\", \"mAP large\",\n",
                "    \"AR max=1\", \"AR max=10\", \"AR max=100\",\n",
                "    \"AR small\", \"AR medium\", \"AR large\",\n",
                "    \"F1@IoU=0.5\"\n",
                "]\n",
                "\n",
                "metrics_values = list(map_stats) + [0.001]\n",
                "\n",
                "metrics_df = pd.DataFrame({\n",
                "    \"Metric\": metrics_names,\n",
                "    \"Value\": metrics_values\n",
                "})\n",
                "\n",
                "print(metrics_df)\n",
                "os.makedirs(\"runs/efficientdet_view_angle\", exist_ok=True)\n",
                "metrics_df.to_csv(\"runs/efficientdet_view_angle/best_model_full_metrics.csv\", index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5134a01c",
            "metadata": {},
            "source": [
                "### Save the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b9c31074",
            "metadata": {},
            "outputs": [],
            "source": [
                "os.makedirs(\"./models\", exist_ok=True)\n",
                "final = False\n",
                "if final:\n",
                "    os.makedirs(\"./models/efficientdet_view_angle\", exist_ok=True)\n",
                "    torch.save(best_model.state_dict(), f\"./models/efficientdet_view_angle/FINAL_epochs{num_epochs}_lr_{lr}_weight_{weight_decay}_view_angle.pt\")\n",
                "elif augmentation:\n",
                "    os.makedirs(\"./models/augmentation\", exist_ok=True)\n",
                "    torch.save(best_model.state_dict(), f\"./models/augmentation/efficientdet_epochs{num_epochs}_lr_{lr}_weight_{weight_decay}_view_angle.pt\")\n",
                "else:\n",
                "    torch.save(best_model.state_dict(), f\"./models/efficientdet_epochs{num_epochs}_lr_{lr}_weight_{weight_decay}_view_angle.pt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bf34afdd",
            "metadata": {},
            "source": [
                "### Plotting the losses for the view angle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6f698c98",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "\n",
                "plt.plot(range(1, num_epochs + 1), train_box_losses,\n",
                "         label='Train Box Loss', marker='o')\n",
                "\n",
                "plt.plot(range(1, num_epochs + 1), train_cls_losses,\n",
                "         label='Train Classification Loss', marker='o')\n",
                "\n",
                "plt.title(\"Training Losses Over Epochs\")\n",
                "plt.xlabel(\"Epoch\")\n",
                "plt.ylabel(\"Loss\")\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b9c7b963",
            "metadata": {},
            "source": [
                "### Plotting the F1-score for each epoch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "017bc362",
            "metadata": {},
            "outputs": [],
            "source": [
                "epochs = range(1, num_epochs + 1)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(\n",
                "    epochs,\n",
                "    val_f1_scores,\n",
                "    marker=\"o\",\n",
                "    linestyle=\"-\",\n",
                "    label=\"Validation F1-score\"\n",
                ")\n",
                "\n",
                "plt.xlabel(\"Epoch\")\n",
                "plt.ylabel(\"F1-score\")\n",
                "plt.title(\"Validation F1-score vs Epochs\")\n",
                "plt.grid(True)\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f748c9da",
            "metadata": {},
            "source": [
                "## 4. Analytics & Visualization\n",
                "\n",
                "Analyze the detections on the validation set. I will count the number of detected signs and visualize the results. I apply inference on the validation set which are unlabelled unseen examples."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7d085682",
            "metadata": {},
            "source": [
                "### Plot of F1-Score vs Confidence Threshold"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f30a5225",
            "metadata": {},
            "outputs": [],
            "source": [
                "confidence_thresholds = np.linspace(0.1, 0.95, 18)\n",
                "\n",
                "f1_val_scores = []\n",
                "f1_threshold = 0.0\n",
                "best_thresh = 0.0\n",
                "for thresh in confidence_thresholds:\n",
                "    f1 = f1_score_by_iou(best_model, val_loader, device, config, iou_threshold=0.5, score_threshold=thresh)\n",
                "    f1_val_scores.append(f1)\n",
                "    print(f\"Threshold: {thresh:.2f}, F1 Score: {f1:.4f}\")\n",
                "    if f1 > f1_threshold:\n",
                "        f1_threshold = f1\n",
                "        best_thresh = thresh\n",
                "\n",
                "plt.figure(figsize=(8,5))\n",
                "plt.plot(confidence_thresholds, f1_val_scores, marker='o')\n",
                "plt.title(\"F1 Score vs Confidence Threshold\")\n",
                "plt.xlabel(\"Confidence Threshold\")\n",
                "plt.ylabel(\"F1 Score\")\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6d8e9fe8",
            "metadata": {},
            "outputs": [],
            "source": [
                "from effdet import DetBenchPredict\n",
                "\n",
                "eval_model = DetBenchPredict(best_model.model)\n",
                "eval_model.to(device)\n",
                "eval_model.eval()\n",
                "\n",
                "total_detected_signs = 0\n",
                "results_summary = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for img, target in val_dataset:\n",
                "        img_batch = img.unsqueeze(0).to(device)\n",
                "        prediction = eval_model(img_batch)[0]\n",
                "        \n",
                "        # EfficientDet output: [num_dets, 6] -> [x1, y1, x2, y2, score, class]\n",
                "        keep = prediction[:, 4] > best_thresh\n",
                "        final_dets = prediction[keep]\n",
                "        \n",
                "        count = len(final_dets)\n",
                "        total_detected_signs += count\n",
                "        \n",
                "        results_summary.append({\n",
                "            \"ImageID\": target[\"image_id\"].item(),\n",
                "            \"DetectedSigns\": count,\n",
                "            \"Labels\": [CLASS_ID_TO_NAME.get(int(det[5].item()), \"Unknown\") for det in final_dets],\n",
                "            \"Labelids\": [int(det[5].item()) for det in final_dets],\n",
                "            \"Scores\": [det[4].item() for det in final_dets],\n",
                "            \"Boxes\": [det[:4].tolist() for det in final_dets]\n",
                "        })\n",
                "\n",
                "print(f\"Total signs detected in validation set: {total_detected_signs}\")\n",
                "print(\"Results summary:\")\n",
                "for res in results_summary:\n",
                "    print(res)\n",
                "\n",
                "# Save results to a text file\n",
                "os.makedirs(\"./results\", exist_ok=True)\n",
                "with open(f\"./results/results_view_angle_epochs{num_epochs}_threshold{best_thresh}.txt\", \"w\") as f:\n",
                "    for res in results_summary:\n",
                "        f.write(f\"{res}\\n\")\n",
                "    f.write(f\"Total detected signs: {total_detected_signs}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9456f473",
            "metadata": {},
            "source": [
                "### Qualitative results and Visualisation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e9f3c1fa",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nVisualizing Sample Predictions:\")\n",
                "for i in range(len(val_dataset)):\n",
                "    img, target = val_dataset[i]\n",
                "    with torch.no_grad():\n",
                "        img_batch = img.unsqueeze(0).to(device)\n",
                "        prediction = eval_model(img_batch)[0]\n",
                "    \n",
                "    gt_labels = [CLASS_ID_TO_NAME.get(l.item(), \"Unknown\") for l in target['labels']]\n",
                "    print(f\"Sample {i+1} Ground Truth: {gt_labels}\")\n",
                "    visualize_predictions(img, prediction, CLASS_ID_TO_NAME, threshold=best_thresh)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7bb6fc2a",
            "metadata": {},
            "source": [
                "## Clean up memory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4ccfa5f9",
            "metadata": {},
            "outputs": [],
            "source": [
                "import gc\n",
                "import torch\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.close(\"all\")\n",
                "torch.cuda.empty_cache()\n",
                "gc.collect()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ari50",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
